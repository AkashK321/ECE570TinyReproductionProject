<!DOCTYPE html>
<html lang="en"><head>
<script src="CheckpointSlides_files/libs/clipboard/clipboard.min.js"></script>
<script src="CheckpointSlides_files/libs/quarto-html/tabby.min.js"></script>
<script src="CheckpointSlides_files/libs/quarto-html/popper.min.js"></script>
<script src="CheckpointSlides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="CheckpointSlides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="CheckpointSlides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="CheckpointSlides_files/libs/quarto-html/quarto-syntax-highlighting-1fe81d0376b2c50856e68e651e390326.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.23">

  <meta name="author" content="Akash Kumar">
  <title>Project Checkpoint 2: SG-LSTM Tiny Reproduction</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="CheckpointSlides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="CheckpointSlides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="CheckpointSlides_files/libs/revealjs/dist/theme/quarto-534cd8e3a96973385dffff3f4709048d.css">
  <link href="CheckpointSlides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="CheckpointSlides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="CheckpointSlides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="CheckpointSlides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Project Checkpoint 2: SG-LSTM Tiny Reproduction</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Akash Kumar 
</div>
</div>
</div>

</section>
<section id="slide-1-updated-problem-statement-goal" class="slide level2">
<h2>Slide 1: Updated Problem Statement &amp; Goal</h2>
<p><strong>Problem Statement:</strong> Predicting pedestrian trajectories in dense crowds is a critical task for autonomous systems. Standard models often treat each person independently, ignoring the fact that people frequently move in <strong>social groups</strong>, which strongly influences their collective path.</p>
<p><strong>Primary Goal &amp; Hypothesis:</strong> This project is a “Tiny Reproduction” to verify the core claim of the <em>SG-LSTM</em> paper. The central hypothesis remains the same: <strong>An LSTM-based model that explicitly incorporates social group dynamics will achieve more accurate trajectory predictions (lower error) than a strong baseline that only models individual-to-individual interactions.</strong></p>
<p><em>(There have been no refinements or changes to the primary goal since Checkpoint 1.)</em></p>
</section>
<section id="slide-2-updated-methodology-progress" class="slide level2">
<h2>Slide 2: Updated Methodology &amp; Progress</h2>
<p><strong>Updated Methodology:</strong> The approach remains to distill the paper’s idea into a focused experiment.<br>
1. <strong>Baseline Model:</strong> I am implementing a <strong>Vanilla LSTM</strong> Encoder-Decoder as a foundational baseline. This model makes predictions based <em>only</em> on a pedestrian’s own past trajectory, containing no social awareness.<br>
2. <strong>Proposed Model:</strong> After establishing the baseline, I will implement the simplified SG-LSTM to show a similar level of improvement as demonstrated in the reference paper.</p>
<p><strong>Progress Since Checkpoint 1:</strong> * <strong>Data Pipeline:</strong> A robust <code>data_loader.py</code> has been fully implemented and verified. It correctly parses the Zara01 dataset, processes individual trajectories, and generates batches of <code>(observation, prediction)</code> tensors for training. * <strong>Baseline Model Implemented:</strong> The Vanilla LSTM model architecture has been coded as a <code>torch.nn.Module</code> in <code>vanilla_lstm_model.py</code>. * <strong>Training Script Implemented:</strong> A complete <code>train.py</code> script has been developed. It handles the training loop, loss calculation, optimization, and final evaluation using ADE and FDE metrics.</p>
</section>
<section id="slide-3-code-snippet-1-model-definition" class="slide level2">
<h2>Slide 3: Code Snippet 1 (Model Definition)</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="co"># From vanilla_lstm_model.py</span></span>
<span id="cb1-2"><a href=""></a></span>
<span id="cb1-3"><a href=""></a><span class="kw">class</span> VanillaLSTM(nn.Module):</span>
<span id="cb1-4"><a href=""></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embedding_dim<span class="op">=</span><span class="dv">64</span>, hidden_dim<span class="op">=</span><span class="dv">64</span>, num_layers<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-5"><a href=""></a>        <span class="bu">super</span>(VanillaLSTM, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-6"><a href=""></a>        <span class="va">self</span>.hidden_dim <span class="op">=</span> hidden_dim</span>
<span id="cb1-7"><a href=""></a></span>
<span id="cb1-8"><a href=""></a>        <span class="co"># Input embedding layer</span></span>
<span id="cb1-9"><a href=""></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Linear(<span class="dv">2</span>, embedding_dim)</span>
<span id="cb1-10"><a href=""></a>        </span>
<span id="cb1-11"><a href=""></a>        <span class="co"># LSTM Encoder</span></span>
<span id="cb1-12"><a href=""></a>        <span class="va">self</span>.encoder <span class="op">=</span> nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-13"><a href=""></a>        </span>
<span id="cb1-14"><a href=""></a>        <span class="co"># LSTM Decoder</span></span>
<span id="cb1-15"><a href=""></a>        <span class="va">self</span>.decoder <span class="op">=</span> nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-16"><a href=""></a>        </span>
<span id="cb1-17"><a href=""></a>        <span class="co"># Output layer</span></span>
<span id="cb1-18"><a href=""></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_dim, <span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="slide-4-explanation-of-snippet-1" class="slide level2">
<h2>Slide 4: Explanation of Snippet 1</h2>
<p><strong>What the code does:</strong></p>
<p>This snippet defines the architecture of my essential baseline model: a Vanilla LSTM with an encoder-decoder structure.</p>
<ul>
<li><code>embedding</code>: A linear layer that projects the input (x, y) coordinates into a higher-dimensional space, allowing the model to learn a richer representation.</li>
<li><code>encoder</code>: An LSTM layer that processes the sequence of observed trajectory points and “encodes” the motion information into its final hidden and cell states.</li>
<li><code>decoder</code>: A second LSTM layer that takes the final states from the encoder and autoregressively predicts the future trajectory, one step at a time.</li>
<li><code>fc</code>: A final linear layer that maps the hidden state from the decoder back to a 2D (x, y) coordinate for the final prediction.</li>
</ul>
<p><strong>Why this is a key component:</strong></p>
<p>This is the <strong>scientific control</strong> for the entire experiment. It represents the simplest reasonable approach to trajectory prediction. By training and evaluating this model first, it establishes a performance baseline (in terms of ADE/FDE) that has zero social awareness. The goal of SG-LSTM will be to demonstrate a quantifiable improvement over this fundamental benchmark.</p>
</section>
<section id="slide-5-code-snippet-2-training-loop" class="slide level2">
<h2>Slide 5: Code Snippet 2 (Training Loop)</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="co"># From train.py</span></span>
<span id="cb2-2"><a href=""></a></span>
<span id="cb2-3"><a href=""></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb2-4"><a href=""></a>    model.train() </span>
<span id="cb2-5"><a href=""></a>    epoch_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb2-6"><a href=""></a>    </span>
<span id="cb2-7"><a href=""></a>    <span class="cf">for</span> batch_idx, (obs_traj, pred_traj_true) <span class="kw">in</span> <span class="bu">enumerate</span>(loader):</span>
<span id="cb2-8"><a href=""></a>        <span class="co"># Move data to the device</span></span>
<span id="cb2-9"><a href=""></a>        obs_traj <span class="op">=</span> obs_traj.to(device)</span>
<span id="cb2-10"><a href=""></a>        pred_traj_true <span class="op">=</span> pred_traj_true.to(device)</span>
<span id="cb2-11"><a href=""></a>        <span class="co"># Zero the gradients</span></span>
<span id="cb2-12"><a href=""></a>        optimizer.zero_grad()</span>
<span id="cb2-13"><a href=""></a>        <span class="co"># Forward pass: get model prediction</span></span>
<span id="cb2-14"><a href=""></a>        pred_traj_fake <span class="op">=</span> model(obs_traj, pred_len<span class="op">=</span>pred_len)</span>
<span id="cb2-15"><a href=""></a>        <span class="co"># Calculate the loss</span></span>
<span id="cb2-16"><a href=""></a>        loss <span class="op">=</span> loss_fn(pred_traj_fake, pred_traj_true)</span>
<span id="cb2-17"><a href=""></a>        epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb2-18"><a href=""></a>        <span class="co"># Backward pass and optimization</span></span>
<span id="cb2-19"><a href=""></a>        loss.backward()</span>
<span id="cb2-20"><a href=""></a>        optimizer.step()</span>
<span id="cb2-21"><a href=""></a></span>
<span id="cb2-22"><a href=""></a>    avg_epoch_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(loader)</span>
<span id="cb2-23"><a href=""></a>    loss_history.append(avg_epoch_loss)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="slide-6-explanation-of-snippet-2" class="slide level2">
<h2>Slide 6: Explanation of Snippet 2</h2>
<p><strong>What the code does:</strong></p>
<p>This snippet shows the core training loop from the <code>train.py</code> script. For each epoch (a full pass over the dataset), this code:</p>
<ul>
<li>Iterates through every batch of data provided by the <code>DataLoader</code>.</li>
<li>Moves the observation and ground-truth trajectories to the correct compute device (CPU or GPU).</li>
<li>Performs a forward pass by feeding the observed trajectories to the model to get its predictions.</li>
<li>Calculates the loss (in this case, Mean Squared Error) by comparing the model’s predictions (<code>pred_traj_fake</code>) to the actual future paths (<code>pred_traj_true</code>).</li>
<li>Performs a backward pass (<code>loss.backward()</code>) to compute gradients, and tells the optimizer to <code>step()</code> to update the model’s weights to minimize the loss.</li>
</ul>
<p><strong>Why this is a key component:</strong></p>
<p>This is the engine of the learning process. This loop is where the model actually learns to predict trajectories by iteratively adjusting its internal weights based on its mistakes. Without this component, the model is just an untrained set of layers. The successful implementation of this training loop is the primary milestone achieved since Checkpoint 1, enabling me to obtain the first quantitative results.</p>
</section>
<section id="slide-7-new-preliminary-result" class="slide level2">
<h2>Slide 7: New Preliminary Result</h2>
<p><strong>Result: Baseline Model Performance</strong></p>
<p>The Vanilla LSTM baseline model was trained for 50 epochs on the Zara01 dataset. The training process successfully converged, as shown by the decreasing loss curve. The final quantitative performance on the training data was measured using Average Displacement Error (ADE) and Final Displacement Error (FDE).</p>
<p>Multiple values were tested for number of layers and learning rate. The lowest error metrics were generated with a Vanilla-LSTM model that has 10 layers and a learning rate of 0.0005</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Metric</th>
<th style="text-align: center;">Value (in meters)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">ADE</td>
<td style="text-align: center;">0.6604</td>
</tr>
<tr class="even">
<td style="text-align: left;">FDE</td>
<td style="text-align: center;">0.9725</td>
</tr>
</tbody>
</table>
<p><img data-src="https://github.com/AkashK321/ECE570TinyReproductionProject/blob/main/plots/64_64_10/train_0.0005_50/training_loss.png?raw=true" alt="Training Loss Curve for the Baseline LSTM Model"> <img data-src="https://github.com/AkashK321/ECE570TinyReproductionProject/blob/main/plots/64_64_10/train_0.0005_50/evaluation_examples.png?raw=true" alt="Evaluation Examples"></p>
</section>
<section id="slide-8-result-analysis-next-steps" class="slide level2 scrollable">
<h2>Slide 8: Result Analysis &amp; Next Steps</h2>
<p><strong>Result Analysis:</strong></p>
<p>The quantitative results (ADE: 0.6604m, FDE: 0.9725m) establish a strong performance baseline for the Vanilla LSTM model after hyperparameter tuning (10 layers, LR=0.0005) on the Zara01 dataset. The training loss curve confirms successful convergence, indicating the model learned effectively from the data. Additionally, the ADE and FDE are similar to the results presented within the SG-LSTM paper where they found the Vanilla-LSTM model to have an ADE of 0.60 and FDE of 1.31 when evaluated on the ETH dataset (note: the ETH and Zara01 are standard benchmarks in pedestrian trajectory prediction, thus the evaluation results on both datasets is comparable).</p>
<p>The evaluation examples visually demonstrate the model’s ability to capture general motion trends. However, as expected from a non-social model, it likely struggles in dense interaction zones and doesn’t explicitly account for coordinated group movements visible in the raw data plot (Slide 7, Checkpoint 1). This performance level serves as a direct, quantitative benchmark against which I can measure the impact of incorporating social group dynamics, aligning with the comparison structure in the original SG-LSTM paper.</p>
<p><strong>Next Steps:</strong></p>
<p>Based on the established Vanilla LSTM baseline and the project goal, I will proceed directly to implementing the core components of the SG-LSTM:</p>
<ol type="1">
<li><strong>Implement Heuristic Group Detection:</strong> Develop the planned distance-based clustering pre-processing step to identify potential social groups within the Zara01 data.</li>
<li><strong>Implement the Group LSTM Module:</strong> Code the specific LSTM architecture designed to process and represent the collective motion of identified groups.</li>
<li><strong>Integrate Group Context:</strong> Modify the prediction model to incorporate the information from the Group LSTM module alongside individual trajectory information.</li>
<li><strong>Train and Compare:</strong> Train the simplified SG-LSTM model and compare its ADE/FDE directly against the achieved Vanilla LSTM baseline (ADE: 0.6604, FDE: 0.9725) to test the central hypothesis.</li>
</ol>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="CheckpointSlides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="CheckpointSlides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="CheckpointSlides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="CheckpointSlides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="CheckpointSlides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="CheckpointSlides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="CheckpointSlides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="CheckpointSlides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="CheckpointSlides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="CheckpointSlides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>